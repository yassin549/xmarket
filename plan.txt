# Final Master Plan — *Everything Market* (Vercel-first + Hugging Face LLM)

This is the **final, simplified, action-oriented masterplan**. It fixes the problems we flagged, uses a hybrid serverless + small dedicated host approach (dedicated orderbook + Playwright runner), specifies Hugging Face as the LLM provider (use hosted endpoints or community free API models where available), and reorganizes **stocks/indexes by category** for a clean user experience. I keep principles, concrete artifacts, config, and a tight roadmap so you can implement straight away.

---

# 1 — Guiding Principles (short & binding)

1. **Determinism & Reproducibility:** every published market event is reproducible from `snapshots + ingest logs + config`.
2. **Auditability & Immutability:** every state change creates an append-only `audit_event` with signer, ts, job_id, and HMAC.
3. **Human-in-the-loop for creation:** no automated agent may create stocks/indexes/events without a signed human admin audit_event.
4. **Simplicity & Minimal State:** serverless for stateless; one small dedicated service for low-latency stateful (orderbook).
5. **Idempotency & Exactly-once where needed:** every external ingest/job has `idempotency_key` and tracked in `jobs` table.
6. **Security-first:** HMAC for inter-service auth, nonce+ts replay protection, Vault/Secrets for keys, RBAC.
7. **LLM provenance:** any LLM output used must include verifiable `snapshot_id` references (content-addressed).
8. **User-first organization:** markets grouped by well-defined categories (political, social, economic, tech, sports, culture) and easy discovery.
9. **Observable & Testable:** SLIs defined for ingest freshness, orderbook latency, embedding queue, LLM success; automated restore tests.

---

# 2 — Architecture (concise)

* **Vercel**: frontend (Next.js) + serverless/edge functions (auth, ingest API, admin, blending triggers, read endpoints).
* **Dedicated hosts** (small container/VM):

  * `orderbook-service` (in-memory matching + WAL + snapshot to object storage)
  * `playwright-runner` (headless browser pool for heavy scraping)
* **Managed services**: Neon/Supabase Postgres, Upstash (Redis-like), Vector DB (Pinecone/Supabase Vector), S3-compatible object store, Realtime (Ably/Pusher/Supabase Realtime).
* **LLM & Embeddings**: Hugging Face Inference API (preferred); fallback to managed OpenAI/Replicate if required. Embedding model choices and batch strategy configurable.
* **Secrets**: Vercel Secrets + HashiCorp Vault for high-risk keys.

---

# 3 — Stocks / Indexes taxonomy (user-facing)

All markets (stocks/indexes/events) must be assigned a **type** at creation. Types drive discovery, moderation, and anti-manipulation rules.

Primary types:

* `political` — elections, policy outcomes, geopolitics
* `economic` — CPI, unemployment, economic indicators, macro events
* `social` — viral trends, social sentiment, platform metrics (followers, trends)
* `technology` — product launches, company milestones, model releases
* `finance` — securities, crypto, commodities indices (not real securities trading)
* `culture` — awards, entertainment, cultural events
* `sports` — matches, tournaments, outcomes

Each market has metadata:

* `type` (one of above)
* `subtype` (free text or enumerated for filters)
* `region` (country or global)
* `risk_level` (human-assigned: low/medium/high)
* `created_by` (admin id)
* `human_approval_audit_id` (audit_event id)

UI consequences:

* Filter by type in discover pages.
* Each type has tailored onboarding copy & moderation thresholds (e.g., political has higher human review).
* Type-specific anti-manipulation rules (e.g., stricter source-reputation and delay windows for `political`).

---

# 4 — Contracts & Key Schemas (copy/paste ready)

## 4.1 Realtime message schema (per-channel)

All realtime messages must contain these fields:

```json
{
  "channel":"string",
  "sequence_number":123,
  "event_id":"uuid",
  "ts":"2025-11-24T08:00:00Z",
  "source_of_truth":"string", 
  "producer":"string",
  "payload":{"type":"object"}
}
```

* `sequence_number` is monotonic **per channel** (e.g., `market:BTC-USD`).
* `source_of_truth` = `orderbook_service` | `reality_worker_vX` | `admin_console`.

## 4.2 `/api/v1/ingest` contract

Request body:

```json
{
  "url":"https://...",
  "idempotency_key":"string",
  "metadata":{...}
}
```

Behavior:

* Idempotent by `{job_type="ingest_fetch", idempotency_key}`.
* Allowed content-size ≤ 10MB.
* Auth: HMAC worker secret.

## 4.3 LLM output schema (required)

LLM responses used in the pipeline must match:

```json
{
  "summary":"string",
  "snapshot_ids":["64hexsha256"],
  "sources":["canonical_url_or_snapshot_ref"],
  "confidence":0.0,
  "schema_version":"v1"
}
```

* **No** free-form source strings accepted as canonical proof — prefer `snapshot_id` (sha256 of `<url>|<ts>`).

## 4.4 Jobs / idempotency table (SQL snippet)

(See full SQL in prior plan; put in `src/infra/idempotency/migrations/001_create_jobs.sql`)

---

# 5 — LLM on Hugging Face (how we use it)

1. **Primary option:** Hugging Face Inference API — call hosted model endpoints. Use a robust text-generation model for blending/summary and a lightweight embedding model for vectors (e.g., sentence-transformers family).
2. **If a free community model is acceptable:** use community-hosted inference endpoints on HF where available; confirm rate/availability. If a free API exists for a chosen model, CI must include fallback logic for quotas.
3. **Provenance enforcement:** require `snapshot_ids` in all LLM outputs and store raw outputs to `llm_raw/{call_id}.json`. Validate outputs against JSON Schema; reject otherwise.
4. **Env vars (examples):**

   * `HUGGINGFACE_API_URL` (e.g., `https://api-inference.huggingface.co/models/<model>`)
   * `HUGGINGFACE_API_KEY`
   * `LLM_BATCH_SIZE`
   * `EMBEDDING_MODEL` (model id)
   * `LLM_MODE=enabled|disabled|degraded`

**Decision checkpoint:** Choose the exact Hugging Face model for embeddings and generation in `docs/decisions.md` after testing on sample inputs.

---

# 6 — Orderbook (clear, hardened)

* **Run as a small dedicated container**: keeps sub-200ms latency for matching.
* **Durability:** synchronous WAL append on every accepted order. Snapshot to object store every 10s. WAL replay on startup.
* **API endpoints (orderbook):**

  * `POST /order` (signed) → accept/reject order, write WAL, return `server_order_id`, publish via realtime with channel `market:{symbol}` and `sequence_number` from orderbook.
  * `POST /cancel`
  * `GET /snapshot?symbol=` returns orderbook snapshot + `last_sequence`.
* **Recovery test:** CI must run a kill/replay test ensuring idempotence.
* **Trade-offs:** accept higher IO for fsync every order in production; allow config `fsync_every_n` for staging.

---

# 7 — Playwright runner (clear)

* Small container pool (e.g., 2–4 instances at start).
* API: accept fetch jobs, render page, save raw HTML snapshot to object store, produce `snapshot_id=sha256(url|ts)` and return minimal parsed fields.
* Throttle: per-domain politeness (default 1 req/sec).
* Use queued jobs with `idempotency_key` and DLQ.

---

# 8 — Anti-manipulation & admin workflow (straight rules)

1. **Create stock/index:** must be created only by admin role + recorded `admin_decision` audit_event (multi-sig for political type optional).
2. **Event publishing:** `reality-worker` may only propose `candidate_event`s; `final_event` requires either auto-finalization rules (whitelisted low-risk sources) or human approval.
3. **Rate limits:** source-level rate thresholds; if exceeded → throttle or quarantine source for `MANIP_WINDOW`.
4. **Admin emergency:** `ops_override` flag is allowed for runbook ops only, must produce immediate audit_event and post-mortem.

---

# 9 — UX & Organization (user perspective)

Goal: **instantly discoverable, low cognitive load.**

Top-level UI areas:

1. **Discover** — browse markets by `type` tiles (Political, Economic, Social, Tech, Finance, Culture, Sports). Each tile shows trending markets and filters.
2. **Watchlists** — user watchlists (global + typed lists), alerts (price thresholds, news events).
3. **Market page** — header: title, type badge, human approval status, sources panel (linked snapshots), orderbook panel, timeline (events with `sequence_number`).
4. **Create Request (users)** — non-admin users can **request** new market; creates a `creation_request` tracked in audit log; admins review.
5. **Admin Console** — approve creation, manage backfills, moderate sources, human-in-the-loop queue for `political` & `economic`.
6. **Search** — filter by type, region, risk, recency, source reputation.
7. **Onboarding & Tooltips** — explain categories and moderation thresholds to users, especially for political markets.

UX specifics:

* Type badges with color coding.
* Market listing shows `type`, `region`, `risk_level`, `human_approval` tag.
* For `political` markets, show "This market was human-reviewed on DATE by ADMIN" prominently.

---

# 10 — Observability, SLOs & Alerts (concise)

SLIs & SLOs:

* **Ingest freshness:** 95% of push-enabled feeds processed within 5 min.
* **Orderbook latency:** 99% orders accepted/rejected < 200ms (dedicated).
* **Embedding success:** 99% embeddings stored within 60s.
* **LLM success:** 99% schema-valid outputs under normal token budget.

Alerts:

* > 1% failed ingests for 30m → page Reality lead.
* Orderbook p50 > 200ms for 30m → page Trading lead.
* Embedding queue > 5k items → page Reality infra.
* LLM schema failure rate > 5% → Ops + autoset `LLM_MODE=degraded`.

---

# 11 — Backups & Restore (essentials)

* **Postgres:** hourly incrementals, daily full; restore tested quarterly.
* **Snapshots:** immediately uploaded to object storage with cross-region replication.
* **Orderbook WAL & Snapshot:** snapshot every 10s, WAL retained 7 days; automated restore test in staging monthly.
* **Runbook:** `docs/runbooks/backup_restore.md` with steps to pause ingestion, restore DB, restore orderbook snapshot+WAL, smoke test, unpause.

---

# 12 — Security & Keys (must-have)

* HMAC signing format: `key-id`, `ts`, `nonce`, `signature = HMAC-SHA256(key, method|path|ts|nonce|body)`.
* Nonce cache per `key-id` for 10 min. Ts tolerance ±120s.
* Key rotation: dual-accept for 24h, rotate in Vault + record audit_event.
* RBAC roles: `viewer`, `editor`, `admin`, `super-admin`. Admin actions require 2FA & audit_event.

---

# 13 — File / Repo layout (minimal)

```
/docs/specs/realtime.md
/docs/specs/ingest_api.md
/docs/specs/llm_schemas.md
/docs/decisions.md
/docs/runbooks/orderbook_recovery.md
/src/infra/idempotency/migrations/001_create_jobs.sql
/src/orderbook/ (service + wal + tests)
/src/playwright-runner/ (service + dockerfile)
/src/backend/ (vercel functions)
/src/frontend/ (nextjs app with typed components)
/ops/oncall_matrix.md
/.github/workflows/ci-concurrency-tests.yml
```

---

# 14 — Env vars (concrete list)

```
NEON_DATABASE_URL
PGBOUNCER_URL
UPSTASH_REST_URL
VECTOR_DB_URL
OBJECT_STORE_URL
OBJECT_STORE_KEY
REALTIME_PROVIDER_KEY
HUGGINGFACE_API_URL
HUGGINGFACE_API_KEY
LLM_MODE
EMBEDDING_MODEL
LLM_BATCH_SIZE
ORDERBOOK_WAL_S3_BUCKET
PLAYWRIGHT_RUNNER_URL
```

---

# 15 — Minimal API list (essential endpoints)

* `POST /api/v1/ingest` — (HMAC) create ingest job (idempotent).
* `POST /api/v1/order` — (user JWT) create order (forwards to orderbook).
* `POST /api/v1/admin/action` — (admin JWT) create admin decision (audit_event).
* `GET /api/v1/market/{symbol}/snapshot?since=` — snapshot + last_sequence.
* `POST /api/v1/reality/ingest_callback` — (HMAC) for runner to post snapshot_id & parsed meta.
* `GET /api/v1/search?type=political&region=...` — filtered search.

---

# 16 — 30-/90-day Roadmap (actionable)

**Week 0 (setup)**

1. Create `docs/specs/*` (realtime, ingest, llm).
2. Implement `jobs` table + idempotency logic.
3. Implement HMAC util + nonce cache.
4. Provision Neon, Upstash, object storage, realtime provider.

**Week 1 (core infra)**
5. Build minimal `orderbook-service` with WAL+snapshot + integration test for restart.
6. Deploy Playwright runner (2 instances) and connect `reality-worker` to it.

**Week 2 (LLM + embeddings)**
7. Wire Hugging Face Inference calls with schema validation.
8. Implement embedding batching and vector DB integration.

**Week 3 (frontend & UX)**
9. Create discover UI by `type` + market page with sequence_number handling.
10. Implement admin console for approvals & human-in-loop queue.

**Week 4–12 (stabilize & scale)**
11. Add observability dashboards and alerting rules.
12. Perform backup restore test and orderbook warm-restart test.
13. QA: chaos tests (realtime outage, vector DB failure, LLM schema failure).
14. Public beta with limited markets & explicit human approvals.

---

# 17 — Decision checkpoints (what to pick & when)

1. **Hugging Face model choices** — pick embedding & generation models early (Week 1) after sample runs.
2. **Orderbook strategy** — dedicated container chosen (we already did). Decide sizing & fsync policy in Week 1.
3. **Vector DB provider** — choose managed (Pinecone/Supabase) vs FAISS in Week 2.
4. **Realtime provider** — choose provider with sequence guarantees; implement server-side `sequence_number` regardless.

Record each decision in `docs/decisions.md` with owner & review date.

---

# 18 — Quick checklist for PRs / CI gates

* Has `idempotency` tests for any new ingest path.
* HMAC used for inter-service calls; tests for replay protection.
* LLM outputs validated against JSON Schema; test included.
* Orderbook has WAL & restart test for changes.
* No production secrets in preview envs. CI fails if present.

---

# 19 — Immediate next actions I will produce for you (pick one; I’ll generate it now)

A. Full `docs/specs/realtime.md` with client pseudocode & examples.
B. `orderbook_recovery.md` runbook with exact restore commands and CI test harness.
C. Playwright runner `Dockerfile` + minimal job server code.
D. Hugging Face model selection checklist & sample prompt templates + JSON schemas adapted for HF.

Tell me which to generate and I’ll produce it immediately (inline).
