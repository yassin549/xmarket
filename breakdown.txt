Short summary: you’ll run 4 Railway services — reality-engine, orderbook, backend, and frontend.
The Reality Engine scrapes top-3 news sites, runs the tinyLLama LLM + quick-scorer pipeline and emits per-stock impacts. The Backend receives these impacts, requests the Orderbook for current market pressure (buys vs sells), blends Reality + Market into the Final Price, updates the DB, and broadcasts updates to the Frontend. Admins create stocks/indexes (public can only trade). Below is a complete, one-file technical breakdown: cycles, APIs, schemas, messages, deployment, security, monitoring, and dev flow for Antigravity + Railway.

1. High-level architecture (one-paragraph)

Four independent services (Railway-hosted, separate processes/containers) communicate over HTTP/WebSocket and a message queue (or direct HTTP with WebSocket broadcasts). Each service has a narrow responsibility:

reality-engine — scrapes sources, dedupes, embeds, quick-scores, runs tinyLLama for high-confidence events, produces impact per stock/index and posts to backend.

orderbook — maintains in-memory/persistent orderbooks, matches orders, exposes aggregated market pressure (buy/sell counts, normalized MarketPrice) via API/WebSocket.

backend — orchestrator: accepts reality impacts, fetches orderbook stats, computes FinalPrice (blend), persists scores and events, enforces anti-manipulation & admin flow, exposes REST/WS for frontend.

frontend — React (Vite) SPA: dashboard, order placement UI, realtime charts (Final/Reality/Market), admin interfaces to create stocks/indexes.

Optional infra: Postgres (Railway DB) shared by backend and orderbook for persistence; Redis (optional) for queues, rate limits.

2. Services & responsibilities (detailed)
2.1 reality-engine

Purpose: ingest news, detect events relevant to your stocks/indexes, compute impact using tinyLLama + quick heuristics, publish event impacts.

Major components

scraper: respects robots.txt, uses RSS when available, polite throttle (per details.txt rules).

prefilter: language detection, NER to map article to stock(s)/index(es).

embed & dedupe: batch embed (all-MiniLM-L6-v2), normalized float32 vectors, FAISS in-memory windowed to 6 hours.

quick_scorer: VADER/spaCy + keyword-based quick_score ∈ [-1,1].

llm_runner: tinyLLama call only for groups passing thresholds (LLM_QUICK_THRESHOLD or multi-source); rate-limited via token bucket.

event_builder: computes event_points = event_weight * quick_score * 100 (then capped).

publisher: posts events/impacts to backend API endpoint.

Outputs

POST /api/v1/reality/events to backend with payload including event_id, stocks[], impact_points, summary, sources[], trusted_score, timestamp, llm_mode.

Env & constants

POLL_INTERVAL, LLM_MODE=local|tiny|heuristic, LLM_CALLS_PER_HOUR, SIMILARITY_DUPLICATE=0.88, SIMILARITY_GROUP=0.78, VECTOR_WINDOW_SECONDS=6*3600.

2.2 orderbook

Purpose: accept user orders, match trades, calculate MarketPrice and market pressure (supply/demand).

Major components

OrderBook engine (per-stock): in-memory structure persisted to Postgres for audit and crash recovery.

matching engine: price-time priority, partial fills allowed, deterministic trade IDs (UUID4), UTC timestamps.

market_aggregator: computes normalized MarketPrice on 0..100 scale (MVP uses 0..100 directly).

public APIs:

POST /api/v1/orders — place order

POST /api/v1/cancel — cancel order

GET /api/v1/market/{stock_id}/snapshot — top-of-book + MarketPrice + depth

WS /ws/orders — trade/orderbook events broadcasted

metrics: total buys, total sells, net flow, liquidity depth

Outputs

GET /api/v1/market/{stock_id}/pressure — return {market_price, buy_volume, sell_volume, net_pressure, timestamp}

Persistence

orders, trade_history tables in Postgres.

2.3 backend

Purpose: central coordinator; receives reality impacts, queries orderbook, computes final price blend and persistence, handles admin flows.

Major components

API:

POST /api/v1/reality/ingest — accept reality-engine events

GET /api/v1/stocks/{stock_id}/final — current final price & components

POST /api/v1/admin/stocks — create/edit stocks/indexes (admin only)

GET /api/v1/admin/pending — list pending audits

POST /api/v1/admin/approve — approve audit

WS /ws/updates — broadcast reality_update, market_update, final_update, audit_event

RealityEngineAdapter: validates incoming events, computes event_weight using constants, translates quick_score→points.

Blender: FinalPrice = market_weight * MarketPrice + reality_weight * RealityScore (default market_weight=0.6, reality_weight=0.4).

AntiManipulation: applies MIN_INDEP_SOURCES, SUSPICIOUS_DELTA, max_single_source_influence.

Persistence: scores, events, llm_audit, score_changes, llm_calls tables.

Workflow

Receive reality event.

Validate & compute delta = event_points (cap ±DELTA_CAP).

If suspicious, create llm_audit (pending), broadcast pending review.

Else: call Orderbook /pressure, call Blender to compute FinalPrice, persist scores and score_changes.

Broadcast final_update via WS.

Security

Admin endpoints protected by X-ADMIN-KEY header.

Validate signatures on reality-engine requests (HMAC or API Key).

DB

Postgres: stocks, scores, events, llm_audit, score_changes, orders (if orderbook shares DB).

2.4 frontend

Purpose: user-facing dashboard and trading UI, admin panel for creating stocks/indexes.

Major components

Dashboard shows: FinalPrice, RealityScore, MarketPrice, Chart (Chart.js), EventsList.

Orderbook view & Order entry widget.

Admin UI: create stocks/indexes, review pending audits.

WebSocket client to /ws/updates for live updates.

Actions

Place buy/sell orders that hit orderbook API.

Subscribe to selected stock via WS to get live final_update + event_summary.

Permissions

Public users: trade only (no stock creation).

Admin users: create stocks & approve audits via Admin panel.

3. Data & message contracts (JSON examples)
3.1 Reality → Backend: POST /api/v1/reality/ingest
{
  "event_id": "uuid",
  "timestamp": "2025-11-22T08:00:00Z",
  "stocks": ["ELON","AI_INDEX"],
  "quick_score": 0.72,
  "impact_points": 28.8,
  "summary": "Company X announced large AI contract; positive earnings guidance.",
  "sources": [
    {"id":"source1","url":"https://news.example/article1","trust":0.9}
  ],
  "num_independent_sources": 2,
  "llm_mode": "tiny",
  "raw_meta": {"title":"...","author":"..."}
}


impact_points should already include event_weight * quick_score * 100 cut to ±DELTA_CAP.

3.2 Backend → Orderbook: GET /api/v1/market/{stock}/pressure

Response:

{
  "stock": "ELON",
  "market_price": 66.2,
  "buy_volume": 120.5,
  "sell_volume": 80.0,
  "net_pressure": 40.5,
  "timestamp": "2025-11-22T08:01:02Z"
}

3.3 Backend broadcast (WebSocket) messages

reality_update:

{"type":"reality_update","stock":"ELON","reality_score":72.4,"delta":+2.4,"timestamp":"...","event_id":"..."}


final_update:

{"type":"final_update","stock":"ELON","final_price":68.9,"components":{"market":66.2,"reality":72.4,"weights":{"market":0.6,"reality":0.4}},"timestamp":"..."}


audit_event (pending):

{"type":"audit_event","event_id":"...","stock":"ELON","delta":20,"state":"pending_review"}

4. Cycles & sequences — full lifecycle (step-by-step)

I'll describe three cycles: (A) Reality ingestion cycle; (B) Trading/orderbook cycle; (C) Blending & publish cycle. Each cycle shows responsibilities and handoffs.

4.A Reality ingestion cycle (scrape → impact → publish)

Scrape — reality-engine polls top-3 configured news sites (respecting crawl-delay) every POLL_INTERVAL (e.g., 300s). Use RSS first; fallback to newspaper3k → Playwright if needed.

Prefilter — title/text checked for mention of registered stocks/indexes via spaCy NER and keyword matching.

Embed & dedupe — embed in batches; check FAISS for similarity > SIMILARITY_DUPLICATE=0.88. If duplicate, drop or group.

Quick scoring — compute quick_score (0.4sentiment + 0.3keyword + 0.3*ner_relevance). Clamp [-1,1].

Group — cluster similar docs (>=0.78) to increase num_related_docs. Compute event_weight.

LLM call (selective) — if |quick_score| >= LLM_QUICK_THRESHOLD or num_independent_sources >= MIN_INDEP_SOURCES, call tinyLLama (rate-limited). Parse JSON result: summary, impact_suggestion, rationale.

Finalize impact — compute event_points = event_weight * quick_score * 100, cap ±DELTA_CAP, prepare event record.

Publish — POST the event to backend /api/v1/reality/ingest with HMAC/API key.

Output of this cycle: an event with impact_points per stock, persisted in events table on backend (or inserted by backend).

4.B Trading / Orderbook cycle (user orders → matching → market snapshot)

User submits order via Frontend → orderbook POST /api/v1/orders.

Orderbook validates, inserts into DB (or memory + DB), attempts match:

Match occurs: create trade event(s) (UUID4), update orders, persist trade_history.

Partial fills tracked with filled amounts.

Orderbook computes aggregated market_price (0..100 or normalized mapping).

Orderbook broadcasts market_update over its WS; backend can subscribe or poll market/pressure endpoint for each reality ingestion event.

Frontend receives updates and shows top-of-book, trade notifications.

4.C Blending & publish cycle (backend core)

Backend receives Reality event (4.A).

Anti-manipulation check:

If abs(delta) > SUSPICIOUS_DELTA or single-source caps violated:

Insert audit row llm_audit (approved=false).

Broadcast audit_event pending review (frontend admin sees it).

Do not apply final reality change until admin approval.

Else continue.

Market pressure call:

Call orderbook /api/v1/market/{stock}/pressure to fetch MarketPrice and volumes.

Blending:

FinalPrice = market_weight * MarketPrice + reality_weight * RealityScore (normalize both to same scale).

Example: market=66.2, reality=72.4, weights (0.6,0.4) → final ≈ 68.92.

Persist:

Insert score_changes (old_score, new_score, delta, event_id).

Update scores table with new RealityScore & final (backend centralizes final view).

Broadcast:

Send reality_update (if applicable), market_update (optional), and final_update via backend WS to frontend clients.

Audit logging:

Persist llm_call record if LLM was used: time, mode, truncated input, output hash.

5. Stocks/index lifecycle & permissions

Admin-created only (your product controls which assets exist). Admins create stocks records in DB via POST /api/v1/admin/stocks.

Stock record includes metadata: {symbol, name, description, denom, min_price, max_price, market_weight, reality_weight, initial_score}.

Public users: register & trade against existing stocks only. They cannot create assets.

Indexes: composed assets (e.g., AI_INDEX) — Reality Engine maps articles to one or more underlying stocks and index logic is computed as weighted average of sub-assets.

6. Database schema (core tables) — simplified
-- stocks
stocks(symbol PK, name, description, min_price, max_price, market_weight, reality_weight, created_at)

-- scores
scores(symbol PK, reality_score float, final_price float, confidence float, last_updated timestamptz)

-- events
events(id PK, symbol, impact_points float, quick_score float, summary text, sources jsonb, created_at timestamptz, processed boolean, llm_mode text)

-- llm_audit
llm_audit(id PK, event_id FK, symbol, summary, impact float, sources jsonb, created_at timestamptz, approved boolean, approved_by text, approved_at timestamptz)

-- score_changes
score_changes(id PK, symbol, old_score float, new_score float, delta float, event_id FK, timestamp timestamptz)

-- orders (orderbook)
orders(order_id PK, user_id, symbol, side, type, price float, qty float, filled float, status text, created_at timestamptz)

-- trade_history
trade_history(trade_id PK, buy_order_id FK, sell_order_id FK, symbol, price float, qty float, timestamp timestamptz)

-- llm_calls
llm_calls(id PK, event_id FK, llm_mode, input_hash, output_json jsonb, timestamp)

7. Key constants (single-source, shared config)

Place these in config/constants.py and load as env overrides:

SIMILARITY_DUPLICATE = 0.88
SIMILARITY_GROUP = 0.78
LLM_QUICK_THRESHOLD = 0.45
VECTOR_WINDOW_SECONDS = 6*3600
TAU_SECONDS = 48*3600
DELTA_CAP = 20
EWMA_ALPHA = 0.25
MIN_INDEP_SOURCES = 2
LLM_CALLS_PER_HOUR = 10
SUSPICIOUS_DELTA = 15

8. Security, signing, and auth

Reality → Backend: require HMAC signature header X-SIGNATURE computed with shared REALITY_API_SECRET to prevent spoofing.

Admin endpoints: require X-ADMIN-KEY header; validate using constant-time compare.

Frontend auth: JWT for logged-in users; short-lived tokens for WS. Do not store admin keys client-side.

Rate limits & quotas: implement per-IP and per-service rate limiting; especially enforce LLM_CALLS_PER_HOUR in reality-engine.

9. Deployment on Railway (4 services)

Project: everything-market

Service: reality-engine

Dockerfile: includes Python + playwright optional + tinyLLama binary if using local inference.

Start command: python -m app.reality.main

Env: DATABASE_URL, REALITY_API_SECRET, POLL_INTERVAL, LLM_MODE, LLM_CALLS_PER_HOUR.

Scale: 1 worker. Use Railway schedule or always-on process.

Service: orderbook

Dockerfile: Python service.

Start command: uvicorn app.orderbook:app --host 0.0.0.0 --port $PORT

Env: DATABASE_URL, ADMIN_API_KEY (if orderbook admin ops needed).

Service: backend

Dockerfile + Uvicorn.

Start command: uvicorn app.backend:app --host 0.0.0.0 --port $PORT

Env: DATABASE_URL, ADMIN_API_KEY, REALITY_API_SECRET (shared with reality-engine), LLM_MODE=heuristic (for demo), MIN_INDEP_SOURCES, SUSPICIOUS_DELTA.

Service: frontend

Static hosting (Railway static or Netlify/Vercel), or Docker running Vite preview for dev. Build step outputs static assets served via CDN.

Networking & connectivity

Use private environment variables and Railway plugin to provide DATABASE_URL.

Configure internal connectivity: reality-engine → backend (HTTP). backend → orderbook (HTTP). backend → frontend (WS push) OR direct WS on backend.

10. Admin & audit workflow (human in the loop)

Reality engine sends large impact → backend flags |delta|>SUSPICIOUS_DELTA.

Backend creates llm_audit row and sets event state pending_review.

Admin receives notification in UI and checks:

LLM summary, sources list (URLs), truncated raw text if allowed, quick_score, source trust values.

Admin approves/rejects via Admin UI:

POST /api/v1/admin/approve with {event_id, approve:true, admin_id}.

If approved: apply event and broadcast final_update.

If rejected: mark audit approved=false, do not apply. Optionally, create an explanation entry.

11. Frontend UX flows (what user sees)

Dashboard: choose stock → shows three numbers (Reality, Market, Final), chart plotting FinalPrice (with overlay lines for Reality & Market), events list with LLM rationales (if small).

Trading widget: place limit/market orders, view orderbook, recent trades.

Admin panel: create stock, view pending audits, approve events.

Realtime behavior: when a reality event occurs, show a transient toast + push to EventsList; FinalPrice animates smoothly to new value (use easing to show EWMA effect).

12. Observability & monitoring

Logs: structured JSON logs with service, event_id, symbol.

Metrics:

Reality events/hour, LLM calls/hour, rate-limiter hits

Order volume/day, matching latency

WS client count

Memory & CPU usage of FAISS + LLM binary

Alerts: threshold alerts for LLM calls per hour, scraper 403/429 rates, DB errors, high SUSPICIOUS_DELTA events.

Tracing: optional distributed tracing across reality→backend→orderbook.

13. Testing & CI (recommended)

Unit tests for: quick_scorer, embed_text (deterministic), vector_index (eviction), reality_engine.apply_event, orderbook.matching.

Integration tests: simulate a full cycle:

Insert two news items into reality-engine sources (mock).

Check backend receives event, orderbook returns pressure.

Validate final price computed correctly.

CI (GitHub Actions): run pytest, build Docker images, but do not auto-deploy — follow Railway manual link flow.

14. Implementation notes & gotchas

Keep LLM calls minimal: LLM cost & latency are the biggest risk. Use heuristic LLM_MODE for demo; enable tinyLLama only for high-value runs and run offline or on separate worker.

FAISS memory: evict vectors older than VECTOR_WINDOW_SECONDS to bound memory.

Atomic updates: apply apply_event in a DB transaction — insert score_changes and update scores atomically.

Timezones: store & display UTC ISO8601 only; convert in frontend.

Scaling: split reality-engine scraping and LLM-run tasks into separate worker processes if LLM is heavy.

Ensure idempotency: use make_id(url, published) and check unique constraint on events to avoid duplicates.

15. Developer workflow with Antigravity (how to orchestrate)

One PR per feature (prompts in prompts.txt map to branches).

Use Antigravity to scaffold repo and agents to implement prompts 1–10 (but ensure human review for anything touching LLM or anti-manipulation).

Local dev:

Run orderbook, backend, reality-engine as separate local processes (or use docker-compose with four services but ensure Playwright and LLama binaries are optional).

Deploy to Railway:

Create Railway project → add Postgres plugin → create 4 services and link repo.

Set env vars in Railway dash for each service (e.g., REALITY_API_SECRET, ADMIN_API_KEY, POLL_INTERVAL).

PR gating: require CI tests; do not merge dev → main without passing CI.

16. Example sequence diagram (textual)
[Scraper] --(news items)--> [Reality Engine Prefilter]
[Reality Engine] --(embed/dedupe/quick_score)--> (maybe LLM)
[Reality Engine] --(POST /api/v1/reality/ingest)--> [Backend]
[Backend] --(validate & anti-manipulation)--> (if suspicious) -> [LLM_AUDIT]
[Backend] --(GET /market/pressure)--> [Orderbook]
[Backend] --(compute final)--> [DB persist]
[Backend] --(WS broadcast)--> [Frontend clients]
[Frontend] --(user order)--> [Orderbook] --> [Backend receives market_update via API/WS]
